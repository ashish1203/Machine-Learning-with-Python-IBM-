{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(683, 11)\n",
      "(683, 11)\n",
      "Train set: (546, 9) (546,)\n",
      "Test set: (137, 9) (137,)\n",
      "0.9635036496350365\n",
      "0.9639038982104676\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# Support Vector Machine\n",
    "#SVM works by mapping data to a high-dimensional feature \n",
    "#space so that data points can be categorized, \n",
    "#even when the data are not otherwise linearly separable.\n",
    "\n",
    "#Basically, mapping data into a higher dimensional space is called kernelling.\n",
    "#The mathematical function used for the transformation is known as the kernel function,\n",
    "#1.Linear\n",
    "#2.Polynomial\n",
    "#3.Radial basis function (RBF)\n",
    "#4.Sigmoid\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix # for confusion matrix\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "######data read \n",
    "cell_df = pd.read_csv(\"cell_samples.csv\")\n",
    "cell_df.head() # first five rows complete data\n",
    "#aa=np.shape(cell_df) # overall size data\n",
    "#print(aa) # 699 by 11\n",
    "\n",
    "######check the type of data- Is any categorical data is there or not \n",
    "cell_df.dtypes # this will idea abt the data types involved in the dadatset - row-wise\n",
    "\n",
    "######drop the rows having categorical data - prsent in BareNuc\n",
    "cell_df = cell_df[pd.to_numeric(cell_df['BareNuc'], errors='coerce').notnull()] # 'coerce' - set NAN; notnull- changed into binary\n",
    "cell_df['BareNuc']\n",
    "cell_df['BareNuc'] = cell_df['BareNuc'].astype('int') # only int type copy\n",
    "cell_df.dtypes\n",
    "#bb= np.shape(cell_df) # overall size data- 683 by 11\n",
    "#print(bb)\n",
    "\n",
    "######feature data\n",
    "feature_df = cell_df[['Clump', 'UnifSize', 'UnifShape', 'MargAdh', 'SingEpiSize', 'BareNuc', 'BlandChrom', 'NormNucl', 'Mit']]\n",
    "feature_df # data selected from csv\n",
    "X = np.asarray(feature_df) # convert into array\n",
    "X[0:5]\n",
    "\n",
    "######Target class\n",
    "cell_df['Class']\n",
    "cc= np.shape(cell_df) # overall size data- \n",
    "print(cc)\n",
    "cell_df['Class'] = cell_df['Class'].astype('int')\n",
    "dd= np.shape(cell_df) \n",
    "print(dd)\n",
    "y = np.asarray(cell_df['Class'])\n",
    "y [0:5]\n",
    "\n",
    "######Spliting of dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.2, random_state=4) # 20% data split\n",
    "print ('Train set:', X_train.shape,  y_train.shape)\n",
    "print ('Test set:', X_test.shape,  y_test.shape)\n",
    "\n",
    "######Model the SVM with train data- training features and its output\n",
    "######model to predict the value of Class (that is, benign (=2) or malignant (=4)).\n",
    "\n",
    "clf = svm.SVC(kernel='rbf')\n",
    "clf.fit(X_train, y_train) \n",
    "\n",
    "\n",
    "######Predict the test data \n",
    "yhat = clf.predict(X_test)\n",
    "yhat [0:5]\n",
    "\n",
    "\n",
    "######Evaluation of result\n",
    "######Measure the accuracy using confusion matrix\n",
    "cm=confusion_matrix(y_test, yhat)\n",
    "diagonal_sum = cm.trace()\n",
    "sum_of_all_elements = cm.sum()\n",
    "Acc= diagonal_sum/sum_of_all_elements\n",
    "print(Acc)\n",
    "\n",
    "######Score metrices\n",
    "print(f1_score(y_test, yhat, average='weighted') )\n",
    "\n",
    "#print(\"Train set Accuracy: \", metrics.f1_score(y_test, yhat, average='weighted') )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "conda-env-python-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
