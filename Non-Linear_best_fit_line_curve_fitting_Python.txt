# Non-linear regression based on Logistic model


import matplotlib.pyplot as plt
import pandas as pd
import pylab as pl
import numpy as np
from sklearn import linear_model
from scipy.optimize import curve_fit
from sklearn.metrics import r2_score

df = pd.read_csv("china_gdp.csv")
#print(df.head)  # it gives overall rows and column

#print(df.describe()) # this will give the statistic data of data
plt.figure(figsize=(8,5))


x_data, y_data = (df["Year"].values, df["Value"].values)
plt.plot(x_data, y_data, 'ro')
plt.ylabel('Year')
plt.xlabel('Value')
plt.show()

#How to decide the model: if data shows curve in nature then use non-lnear regression model
#design the model based on the curve pattern : quadratic, logarthmetic, squared, sigmoid


# graph shows initial slow then increasing growth and afterwards again slow growth : model will be sigmoid non-linear
# First design our model

def sigmoid(x_data, beta_1 , beta_2):
    y = 1 / (1 + np.exp(-beta_1*(x_data-beta_2)))
    return y

beta_1 = 0.10
beta_2 = 1990.0

#logistic function : observational data are modeled by a function which is a nonlinear combination of the model parameters 
Y_pred = sigmoid(x_data, beta_1 , beta_2) # predicted function with random parameters beta 1 and beta 2

#plot initial prediction against datapoints
plt.plot(x_data, Y_pred*15000000000000)
plt.plot(x_data, y_data, 'ro')

# Now fit our model on our data
#(1) First normalize oyr data points
#(2)  Use curve_fit which uses non-linear least squares to fit our sigmoid function, to data.


# Lets normalize our data
xdata =x_data/max(x_data)
ydata =y_data/max(y_data)

#The best-fit curve is often assumed to be that which minimizes the sum of squared residuals.
popt, pcov = curve_fit(sigmoid, xdata, ydata) # find the optimized parametrs using curve fitting 
#print the final parameters
print(" beta_1 = %f, beta_2 = %f" % (popt[0], popt[1]))
#print (*popt)
x = np.linspace(1960, 2015, 55)
x = x/max(x)
plt.figure(figsize=(8,5))
#y = sigmoid(x, *popt)  # sigmoid function arguments will be : x_data, beta_1, beta_2 

# or 
y = sigmoid(x, popt[0], popt[1]) # using thr optimized paramters we train our model

plt.plot(xdata, ydata, 'ro', label='data')
plt.plot(x,y, linewidth=3.0, label='fit')
plt.legend(loc='best')
plt.ylabel('GDP')
plt.xlabel('Year')
plt.show()


print("Mean absolute error: %.2f" % np.mean(np.absolute(Y_pred - ydata )))
print("Residual sum of squares (MSE): %.2f" % np.mean((Y_pred - ydata ) ** 2))  # difference b/w data point and model estimate 
#print("R2-score: %.2f" % r2_score(Y_pred , y) )

print("Mean absolute error: %.2f" % np.mean(np.absolute(y - ydata )))
print("Residual sum of squares (MSE): %.2f" % np.mean((y - ydata ) ** 2))  # difference b/w data point and model estimate 
