#Agglomerative Hierarchical Clustering- bottom up approach: more popular than Divisive clustering. 

#Agglomerative Clustering: The Agglomerative Clustering class will require two inputs:

# n_clusters: The number of clusters to form as well as the number of centroids to generate.

#linkage: Which linkage criterion to use. The linkage criterion determines which distance to use between sets of observation. The algorithm will merge the pairs of cluster that minimize this criterion

import numpy as np 
import pandas as pd
from sklearn.preprocessing import MinMaxScaler # for normalization within the range min-to-max
from scipy.spatial import distance_matrix 
from sklearn.cluster import AgglomerativeClustering 
from scipy.cluster import hierarchy 
from matplotlib import pyplot as plt

filename = 'cars_clus.csv'
#Read csv
data_frame = pd.read_csv(filename)
print ("Shape of dataset: ", data_frame.shape) # shape will give information about the size of data: row and col
print ("Size of dataset: ", data_frame.size)
#print(data_frame)
#print(data_frame.dtypes)

# DATA CLEANING
# convert pandas dataframe into List:- LIST- 1 dimensional data, Array:- can be anything
aa= data_frame[[ 'sales', 'resale', 'type', 'price', 'engine_s','horsepow', 'wheelbas', 'width', 'length', 'curb_wgt', 'fuel_cap','mpg', 'lnsales']]
print(type(aa))

# convert pandas dataframe into arrays:- LIST- 1 dimensional data, Array:- can be anything
#bb = data_frame[['sales', 'resale', 'type', 'price', 'engine_s','horsepow', 'wheelbas', 'width', 'length', 'curb_wgt', 'fuel_cap','mpg', 'lnsales']] .values  #.astype(float)
#print(type(bb))
aa=aa.apply(pd.to_numeric, errors='coerce')

upd_data = aa.dropna()
upd_data = upd_data.reset_index(drop=True)
upd_data.head(5)
print ("Shape of updated data: ", upd_data.shape)
print ("Size of updated data: ", upd_data.size)

#FEATURE SELECTION
featureset = upd_data[['engine_s',  'horsepow', 'wheelbas', 'width', 'length', 'curb_wgt', 'fuel_cap', 'mpg']] # Select some samples

# NORMALIZATION :- within the range of 0-1

norm_data = featureset.values #returns a numpy array :- .values is used to convert the data into array 
min_max_scaler = MinMaxScaler()
norm_feature_mtx = min_max_scaler.fit_transform(norm_data)
norm_feature_mtx [0:5]

#Clustering
#In agglomerative clustering, at each iteration, the algorithm must update the distance matrix 
#to reflect the distance of the newly formed cluster with the remaining clusters in the forest.

dist_matrix = distance_matrix(norm_feature_mtx,norm_feature_mtx) 
print(dist_matrix)

# MERGING UPWARDS: 
# (1) Maximum or complete linkage minimizes the maximum distance between observations of pairs of clusters.
# (2) Average linkage minimizes the average of the distances between all observations of pairs of clusters.

agglom = AgglomerativeClustering(n_clusters = 6, affinity='euclidean', linkage = 'complete') #AgglomerativeClustering(n_clusters=2, affinity='euclidean', linkage='ward')
agglom.fit(norm_feature_mtx)
agglom.labels_

# ADD LABELS TO DATA FRAME
upd_data['cluster_'] = agglom.labels_
upd_data.head()